#!/usr/bin/env python3
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
æ”¯æŒCSVå¯¼å…¥ã€å¢é‡æ›´æ–°å’Œæ‰¹é‡æ“ä½œ
"""

import os
import sys
import json
import csv
from pathlib import Path
from pymongo import MongoClient, ASCENDING, DESCENDING
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

load_dotenv()

def connect_database():
    """è¿æ¥MongoDBæ•°æ®åº“"""
    mongo_url = os.getenv("MONGO_URL", "mongodb://localhost:27017")
    client = MongoClient(mongo_url)
    db = client.university_matcher
    return db

def create_indexes(db):
    """åˆ›å»ºæ•°æ®åº“ç´¢å¼•"""
    print("åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
    
    try:
        # ç”¨æˆ·é›†åˆç´¢å¼•
        db.users.create_index("created_at")
        print("âœ… ç”¨æˆ·ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  ç”¨æˆ·ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")
    
    try:
        # å¤§å­¦é›†åˆç´¢å¼• - æ›´æ–°ä»¥æ”¯æŒæ–°å­—æ®µ
        # å…ˆåˆ é™¤å¯èƒ½å†²çªçš„ç´¢å¼•
        try:
            db.universities.drop_index("name_1")
            print("ğŸ”„ åˆ é™¤æ—§åç§°ç´¢å¼•")
        except:
            pass
        
        # åˆ›å»ºæ–°ç´¢å¼•
        db.universities.create_index("name", unique=True)  # ç¡®ä¿å¤§å­¦åç§°å”¯ä¸€
        db.universities.create_index("country")
        db.universities.create_index("rank")
        db.universities.create_index([("country", ASCENDING), ("rank", ASCENDING)])
        db.universities.create_index("strengths")
        db.universities.create_index("tuition")
        db.universities.create_index("type")
        db.universities.create_index("school_size")
        db.universities.create_index("tags")
    
        # æ–°å¢å­—æ®µç´¢å¼•
        db.universities.create_index("supports_ed")
        db.universities.create_index("supports_ea")
        db.universities.create_index("supports_rd")
        db.universities.create_index("internship_support_score")
        db.universities.create_index("acceptanceRate")
        db.universities.create_index("intlRate")
        db.universities.create_index("state")
        db.universities.create_index("personality_types")
        
        print("âœ… å¤§å­¦ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  å¤§å­¦ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")
    
    try:
        # è¯„ä¼°ç»“æœç´¢å¼•
        db.parent_evaluations.create_index("user_id")
        db.parent_evaluations.create_index("created_at")
        db.student_personality_tests.create_index("user_id")
        db.student_personality_tests.create_index("created_at")
        print("âœ… è¯„ä¼°ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  è¯„ä¼°ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")
    
    print("ç´¢å¼•åˆ›å»ºå®Œæˆ")

    # å›½é™…å¤§å­¦é›†åˆç´¢å¼•
    try:
        # AU
        db.university_au.create_index("name", unique=True)
        db.university_au.create_index("city")
        db.university_au.create_index("rank")
        db.university_au.create_index("work_integrated_learning")
        db.university_au.create_index("group_of_eight")
        db.university_au.create_index("strengths")
        db.university_au.create_index("tags")
        # UK
        db.university_uk.create_index("name", unique=True)
        db.university_uk.create_index("city")
        db.university_uk.create_index("rank")
        db.university_uk.create_index("foundation_available")
        db.university_uk.create_index("placement_year_available")
        db.university_uk.create_index("russell_group")
        db.university_uk.create_index("strengths")
        db.university_uk.create_index("tags")
        # SG
        db.university_sg.create_index("name", unique=True)
        db.university_sg.create_index("rank")
        db.university_sg.create_index("tuition_grant_available")
        db.university_sg.create_index("strengths")
        db.university_sg.create_index("tags")
        print("âœ… å›½é™…å¤§å­¦ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  å›½é™…å¤§å­¦ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")

def clean_boolean_value(value):
    """æ¸…ç†å¸ƒå°”å€¼"""
    if isinstance(value, str):
        value = value.strip().upper()
        if value in ['TRUE', 'T', 'YES', 'Y', '1']:
            return True
        elif value in ['FALSE', 'F', 'NO', 'N', '0']:
            return False
    return False

def clean_numeric_value(value, default=0, is_float=False):
    """æ¸…ç†æ•°å€¼"""
    if not value or value == '':
        return default
    
    try:
        if is_float:
            return float(value)
        else:
            return int(value)
    except (ValueError, TypeError):
        return default

def import_universities_from_csv(db, csv_file_path, clear_existing=False):
    """ä»CSVæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®"""
    if not os.path.exists(csv_file_path):
        print(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    print(f"ä»CSVæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®: {csv_file_path}")
    
    # æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®
    if clear_existing:
        db.universities.delete_many({})
        print("å·²æ¸…ç©ºç°æœ‰æ•°æ®")
    
    with open(csv_file_path, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        universities = []
        updated_count = 0
        inserted_count = 0
        
        for row_num, row in enumerate(reader, 1):
            try:
                # è°ƒè¯•ï¼šæ˜¾ç¤ºå…³é”®å­—æ®µçš„åŸå§‹å€¼
                if row_num <= 3:  # åªæ˜¾ç¤ºå‰3è¡Œ
                    print(f"ğŸ” ç¬¬{row_num}è¡Œè°ƒè¯•ä¿¡æ¯:")
                    print(f"   acceptanceRate: '{row.get('acceptanceRate', 'NOT_FOUND')}'")
                    print(f"   satRange: '{row.get('satRange', 'NOT_FOUND')}'")
                    print(f"   actRange: '{row.get('actRange', 'NOT_FOUND')}'")
                    print(f"   gpaRange: '{row.get('gpaRange', 'NOT_FOUND')}'")
                    print(f"   applicationDeadline: '{row.get('applicationDeadline', 'NOT_FOUND')}'")
                    print(f"   supports_ed: '{row.get('supports_ed', 'NOT_FOUND')}'")
                    print(f"   supports_ea: '{row.get('supports_ea', 'NOT_FOUND')}'")
                    print(f"   supports_rd: '{row.get('supports_rd', 'NOT_FOUND')}'")
                    print(f"   has_internship_program: '{row.get('has_internship_program', 'NOT_FOUND')}'")
                    print(f"   has_research_program: '{row.get('has_research_program', 'NOT_FOUND')}'")
                    print(f"   internship_support_score: '{row.get('internship_support_score', 'NOT_FOUND')}'")
                    print(f"   schoolSize: '{row.get('schoolSize', 'NOT_FOUND')}'")
                    print(f"   website: '{row.get('website', 'NOT_FOUND')}'")
                    print("   ---")
                
                # æ•°æ®æ¸…æ´—å’Œè½¬æ¢ - é€‚é…schools.csvæ ¼å¼
                university = {
                    "name": row.get("name", "").strip(),
                    "country": row.get("country", "").strip(),
                    "state": row.get("state", "").strip(),
                    "rank": clean_numeric_value(row.get("rank"), 999),
                    "tuition": clean_numeric_value(row.get("tuition"), 0),
                    "intlRate": clean_numeric_value(row.get("intlRate"), 0, True),
                    "type": row.get("type", "private").strip(),
                    "schoolSize": row.get("schoolSize", "medium").strip(),
                    "strengths": [s.strip() for s in row.get("strengths", "").split(",") if s.strip()] if row.get("strengths") else [],
                    "gptSummary": row.get("gptSummary", "").strip(),
                    "logoUrl": "",  # æš‚æ—¶ç•™ç©ºï¼Œåç»­å¯ä»¥æ·»åŠ 
                    "acceptanceRate": clean_numeric_value(row.get("acceptanceRate"), 0, True),
                    "satRange": row.get("satRange", "").strip(),
                    "actRange": row.get("actRange", "").strip(),
                    "gpaRange": row.get("gpaRange", "").strip(),
                    "applicationDeadline": row.get("applicationDeadline", "").strip(),
                    "website": row.get("website", "").strip(),
                    "supports_ed": clean_boolean_value(row.get("supports_ed")),
                    "supports_ea": clean_boolean_value(row.get("supports_ea")),
                    "supports_rd": clean_boolean_value(row.get("supports_rd")),
                    "has_internship_program": clean_boolean_value(row.get("has_internship_program")),
                    "has_research_program": clean_boolean_value(row.get("has_research_program")),
                    "internship_support_score": clean_numeric_value(row.get("internship_support_score"), 5),
                    "personality_types": [s.strip() for s in row.get("personality_types", "").split(",") if s.strip()] if row.get("personality_types") else [],
                    "tags": [s.strip() for s in row.get("tags", "").split(",") if s.strip()] if row.get("tags") else []
                }
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºæ¸…æ´—åçš„å…³é”®å­—æ®µå€¼
                if row_num <= 3:  # åªæ˜¾ç¤ºå‰3è¡Œ
                    print(f"ğŸ”§ ç¬¬{row_num}è¡Œæ¸…æ´—åæ•°æ®:")
                    print(f"   acceptanceRate: {university['acceptanceRate']}")
                    print(f"   satRange: '{university['satRange']}'")
                    print(f"   actRange: '{university['actRange']}'")
                    print(f"   gpaRange: '{university['gpaRange']}'")
                    print(f"   applicationDeadline: '{university['applicationDeadline']}'")
                    print(f"   supports_ed: {university['supports_ed']}")
                    print(f"   supports_ea: {university['supports_ea']}")
                    print(f"   supports_rd: {university['supports_rd']}")
                    print(f"   has_internship_program: {university['has_internship_program']}")
                    print(f"   has_research_program: {university['has_research_program']}")
                    print(f"   internship_support_score: {university['internship_support_score']}")
                    print(f"   schoolSize: '{university['schoolSize']}'")
                    print(f"   website: '{university['website']}'")
                    print("   ---")
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                if not university["name"]:
                    print(f"âš ï¸  ç¬¬{row_num}è¡Œï¼šç¼ºå°‘å¤§å­¦åç§°ï¼Œè·³è¿‡")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆæŒ‰åç§°ï¼‰
                existing = db.universities.find_one({"name": university["name"]})
                if existing:
                    if clear_existing:
                        # å¦‚æœæ¸…ç©ºæ¨¡å¼ï¼Œç›´æ¥æ’å…¥
                        universities.append(university)
                    else:
                        # æ›´æ–°æ¨¡å¼ï¼Œæ›´æ–°ç°æœ‰è®°å½•
                        db.universities.update_one(
                            {"name": university["name"]}, 
                            {"$set": university}
                        )
                        updated_count += 1
                else:
                    universities.append(university)
                
            except Exception as e:
                print(f"âŒ ç¬¬{row_num}è¡Œæ•°æ®é”™è¯¯: {e}")
                print(f"   è¡Œæ•°æ®: {row}")
                continue
        
        # æ‰¹é‡æ’å…¥æ–°æ•°æ®
        if universities:
            try:
                result = db.universities.insert_many(universities)
                inserted_count = len(result.inserted_ids)
                print(f"âœ… æˆåŠŸæ’å…¥ {inserted_count} æ‰€æ–°å¤§å­¦")
            except Exception as e:
                print(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
                # å°è¯•é€ä¸ªæ’å…¥
                for uni in universities:
                    try:
                        db.universities.insert_one(uni)
                        inserted_count += 1
                    except Exception as e2:
                        print(f"âŒ æ’å…¥å¤±è´¥ {uni['name']}: {e2}")
        
        print(f"ğŸ“Š å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted_count} æ‰€ï¼Œæ›´æ–° {updated_count} æ‰€")


def _read_xlsx_rows(file_path, expected_headers):
    try:
        import openpyxl
    except Exception as e:
        raise RuntimeError("éœ€è¦å®‰è£… openpyxl ä»¥è¯»å–Excelæ–‡ä»¶: pip install openpyxl") from e
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active
    headers = [str(c.value).strip() if c.value is not None else "" for c in next(ws.iter_rows(min_row=1, max_row=1))[0:len(expected_headers)]]
    if [h.strip() for h in headers] != expected_headers:
        raise RuntimeError(f"Excelè¡¨å¤´ä¸åŒ¹é…ï¼ŒæœŸæœ›: {expected_headers}ï¼Œå®é™…: {headers}")
    for row in ws.iter_rows(min_row=2):
        values = [c.value for c in row[:len(expected_headers)]]
        yield dict(zip(expected_headers, values))


def import_au_from_excel(db, file_path, clear_existing=False):
    expected = [
        "name","country","city","rank","tuition_local","currency","tuition_usd","study_length_years",
        "intakes","english_requirements","requires_english_test","group_of_eight","work_integrated_learning",
        "placement_rate","post_study_visa_years","scholarship_available","strengths","tags","intlRate","website"
    ]
    if clear_existing:
        db.university_au.delete_many({})
    inserted, updated = 0, 0
    for row in _read_xlsx_rows(file_path, expected):
        row["strengths"] = [s.strip() for s in (row.get("strengths") or "").split(",") if s and str(s).strip()]
        row["tags"] = [s.strip() for s in (row.get("tags") or "").split(",") if s and str(s).strip()]
        existing = db.university_au.find_one({"name": row["name"]})
        if existing and not clear_existing:
            db.university_au.update_one({"_id": existing["_id"]}, {"$set": row})
            updated += 1
        else:
            db.university_au.insert_one(row)
            inserted += 1
    print(f"âœ… AU å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted}ï¼Œæ›´æ–° {updated}")


def import_uk_from_excel(db, file_path, clear_existing=False):
    expected = [
        "name","country","city","rank","tuition_local","currency","tuition_usd","study_length_years",
        "ucas_deadline_type","typical_offer_alevel","typical_offer_ib","foundation_available","russell_group",
        "placement_year_available","interview_required","admissions_tests","personal_statement_weight","strengths",
        "tags","intlRate","website","scholarship_available"
    ]
    if clear_existing:
        db.university_uk.delete_many({})
    inserted, updated = 0, 0
    for row in _read_xlsx_rows(file_path, expected):
        row["strengths"] = [s.strip() for s in (row.get("strengths") or "").split(",") if s and str(s).strip()]
        row["tags"] = [s.strip() for s in (row.get("tags") or "").split(",") if s and str(s).strip()]
        existing = db.university_uk.find_one({"name": row["name"]})
        if existing and not clear_existing:
            db.university_uk.update_one({"_id": existing["_id"]}, {"$set": row})
            updated += 1
        else:
            db.university_uk.insert_one(row)
            inserted += 1
    print(f"âœ… UK å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted}ï¼Œæ›´æ–° {updated}")


def import_sg_from_excel(db, file_path, clear_existing=False):
    expected = [
        "name","country","city","rank","tuition_local","currency","tuition_usd","study_length_years",
        "tuition_grant_available","tuition_grant_bond_years","interview_required","essay_or_portfolio_required",
        "coop_or_internship_required","industry_links_score","exchange_opportunities_score","strengths","tags",
        "intlRate","website","scholarship_available"
    ]
    if clear_existing:
        db.university_sg.delete_many({})
    inserted, updated = 0, 0
    for row in _read_xlsx_rows(file_path, expected):
        row["strengths"] = [s.strip() for s in (row.get("strengths") or "").split(",") if s and str(s).strip()]
        row["tags"] = [s.strip() for s in (row.get("tags") or "").split(",") if s and str(s).strip()]
        existing = db.university_sg.find_one({"name": row["name"]})
        if existing and not clear_existing:
            db.university_sg.update_one({"_id": existing["_id"]}, {"$set": row})
            updated += 1
        else:
            db.university_sg.insert_one(row)
            inserted += 1
    print(f"âœ… SG å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted}ï¼Œæ›´æ–° {updated}")

def import_from_json(db, json_file_path, clear_existing=False):
    """ä»JSONæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®"""
    if not os.path.exists(json_file_path):
        print(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return
    
    print(f"ä»JSONæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®: {json_file_path}")
    
    try:
        with open(json_file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        if clear_existing:
            db.universities.delete_many({})
            print("å·²æ¸…ç©ºç°æœ‰æ•°æ®")
        
        if isinstance(data, list):
            universities = data
        elif isinstance(data, dict) and "universities" in data:
            universities = data["universities"]
        else:
            print("âŒ JSONæ ¼å¼é”™è¯¯ï¼šåº”è¯¥æ˜¯å¤§å­¦æ•°ç»„æˆ–åŒ…å«universitieså­—æ®µçš„å¯¹è±¡")
            return
        
        # å¤„ç†æ•°æ®
        inserted_count = 0
        updated_count = 0
        
        for uni in universities:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.universities.find_one({"name": uni["name"]})
                if existing:
                    if clear_existing:
                        db.universities.insert_one(uni)
                        inserted_count += 1
                    else:
                        db.universities.update_one(
                            {"name": uni["name"]}, 
                            {"$set": uni}
                        )
                        updated_count += 1
                else:
                    db.universities.insert_one(uni)
                    inserted_count += 1
            except Exception as e:
                print(f"âŒ å¤„ç†å¤§å­¦ {uni.get('name', 'Unknown')} å¤±è´¥: {e}")
        
        print(f"ğŸ“Š JSONå¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted_count} æ‰€ï¼Œæ›´æ–° {updated_count} æ‰€")
        
    except Exception as e:
        print(f"âŒ JSONæ–‡ä»¶è¯»å–å¤±è´¥: {e}")

def export_to_csv(db, output_file="universities_export.csv"):
    """å¯¼å‡ºæ•°æ®åº“ä¸­çš„å¤§å­¦æ•°æ®åˆ°CSVæ–‡ä»¶"""
    print(f"å¯¼å‡ºå¤§å­¦æ•°æ®åˆ°: {output_file}")
    
    # åˆ›å»ºdataç›®å½•
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(exist_ok=True)
    
    output_path = data_dir / output_file
    
    # è·å–æ‰€æœ‰å¤§å­¦æ•°æ®
    universities = list(db.universities.find({}, {"_id": 0}).sort("rank", 1))
    
    if not universities:
        print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰å¤§å­¦æ•°æ®")
        return
    
    # å†™å…¥CSV
    with open(output_path, 'w', encoding='utf-8', newline='') as file:
        if universities:
            fieldnames = universities[0].keys()
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(universities)
    
    print(f"âœ… æˆåŠŸå¯¼å‡º {len(universities)} æ‰€å¤§å­¦åˆ° {output_path}")

def show_database_stats(db):
    """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 40)
    
    total_universities = db.universities.count_documents({})
    print(f"æ€»å¤§å­¦æ•°é‡: {total_universities}")
    
    if total_universities > 0:
        # æ’ååˆ†å¸ƒ
        top10 = db.universities.count_documents({"rank": {"$lte": 10}})
        top20 = db.universities.count_documents({"rank": {"$lte": 20}})
        top50 = db.universities.count_documents({"rank": {"$lte": 50}})
        
        print(f"å‰10å: {top10} æ‰€")
        print(f"å‰20å: {top20} æ‰€")
        print(f"å‰50å: {top50} æ‰€")
        
        # ç±»å‹åˆ†å¸ƒ
        private_count = db.universities.count_documents({"type": "private"})
        public_count = db.universities.count_documents({"type": "public"})
        print(f"ç§ç«‹å¤§å­¦: {private_count} æ‰€")
        print(f"å…¬ç«‹å¤§å­¦: {public_count} æ‰€")
        
        # è§„æ¨¡åˆ†å¸ƒ
        small_count = db.universities.count_documents({"schoolSize": "small"})
        medium_count = db.universities.count_documents({"schoolSize": "medium"})
        large_count = db.universities.count_documents({"schoolSize": "large"})
        print(f"å°å‹å­¦æ ¡: {small_count} æ‰€")
        print(f"ä¸­å‹å­¦æ ¡: {medium_count} æ‰€")
        print(f"å¤§å‹å­¦æ ¡: {large_count} æ‰€")
        
        # å›½å®¶åˆ†å¸ƒ
        usa_count = db.universities.count_documents({"country": "USA"})
        print(f"ç¾å›½å¤§å­¦: {usa_count} æ‰€")
        
        # å¹³å‡å­¦è´¹
        avg_tuition = db.universities.aggregate([
            {"$group": {"_id": None, "avg": {"$avg": "$tuition"}}}
        ]).next()["avg"]
        print(f"å¹³å‡å­¦è´¹: ${avg_tuition:,.0f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤§å­¦æ•°æ®åº“ç®¡ç†å·¥å…·")
    print("=" * 50)
    
    # è¿æ¥æ•°æ®åº“
    try:
        db = connect_database()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºç´¢å¼•
    create_indexes(db)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶ï¼ˆç¾å›½/é»˜è®¤ï¼‰
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(exist_ok=True)
    
    # ä¼˜å…ˆæ£€æŸ¥schools.csvï¼Œç„¶åæ˜¯universities.csv
    schools_csv = data_dir / "schools.csv"
    universities_csv = data_dir / "universities.csv"
    json_file = data_dir / "universities.json"
    
    if schools_csv.exists():
        print(f"ğŸ“ æ‰¾åˆ°å­¦æ ¡æ•°æ®æ–‡ä»¶: {schools_csv}")
        choice = input("æ˜¯å¦ä»schools.csvå¯¼å…¥æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            clear_existing = clear_choice == 'y'
            import_universities_from_csv(db, str(schools_csv), clear_existing)
    elif universities_csv.exists():
        print(f"ğŸ“ æ‰¾åˆ°å¤§å­¦æ•°æ®æ–‡ä»¶: {universities_csv}")
        choice = input("æ˜¯å¦ä»universities.csvå¯¼å…¥æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            clear_existing = clear_choice == 'y'
            import_universities_from_csv(db, str(universities_csv), clear_existing)
    elif json_file.exists():
        print(f"ğŸ“ æ‰¾åˆ°JSONæ–‡ä»¶: {json_file}")
        choice = input("æ˜¯å¦ä»JSONå¯¼å…¥æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            clear_existing = clear_choice == 'y'
            import_from_json(db, str(json_file), clear_existing)
    # å›½é™…æ•°æ®ï¼ˆAU/UK/SGï¼‰ - ä¼˜å…ˆè¯»å–Excel
    intl_dir = data_dir / "international"
    intl_dir.mkdir(exist_ok=True)

    au_xlsx = intl_dir / "AUSTRALIA.xlsx"
    uk_xlsx = intl_dir / "UK.xlsx"
    sg_xlsx = intl_dir / "SINGAPORE.xlsx"

    # å¦‚æ— Excelï¼Œå°è¯•ä½¿ç”¨å·²æœ‰CSVç»“æ„ç”ŸæˆExcelæ ·ä¾‹
    def ensure_sample_excels():
        try:
            import openpyxl
        except Exception:
            print("âš ï¸ æœªå®‰è£…openpyxlï¼Œè·³è¿‡ç”ŸæˆExcelæ ·ä¾‹ã€‚å¯å®‰è£…åé‡è¯•: pip install openpyxl")
        return
        if not au_xlsx.exists():
            wb = openpyxl.Workbook(); ws = wb.active
            ws.append(["name","country","city","rank","tuition_local","currency","tuition_usd","study_length_years","intakes","english_requirements","requires_english_test","group_of_eight","work_integrated_learning","placement_rate","post_study_visa_years","scholarship_available","strengths","tags","intlRate","website"])
            ws.append(["University of Melbourne","Australia","Melbourne",32,48000,"AUD",32000,3.0,"Feb, Jul","IELTS 6.5 no<6.0",True,True,True,0.85,4.0,True,"CS,Engineering,Business","Go8,WIL",0.35,"https://www.unimelb.edu.au"])  # ç¤ºä¾‹
            wb.save(au_xlsx)
            print(f"ğŸ§ª å·²ç”Ÿæˆæ ·ä¾‹: {au_xlsx}")
        if not uk_xlsx.exists():
            wb = openpyxl.Workbook(); ws = wb.active
            ws.append(["name","country","city","rank","tuition_local","currency","tuition_usd","study_length_years","ucas_deadline_type","typical_offer_alevel","typical_offer_ib","foundation_available","russell_group","placement_year_available","interview_required","admissions_tests","personal_statement_weight","strengths","tags","intlRate","website","scholarship_available"])
            ws.append(["University of Manchester","United Kingdom","Manchester",52,28000,"GBP",35000,3.0,"Main(1/31)","AAA","36-38 HL 666",True,True,True,False,"TMUA",7,"CS,Engineering,Business","Russell,Placement",0.30,"https://www.manchester.ac.uk",True])
            wb.save(uk_xlsx)
            print(f"ğŸ§ª å·²ç”Ÿæˆæ ·ä¾‹: {uk_xlsx}")
        if not sg_xlsx.exists():
            wb = openpyxl.Workbook(); ws = wb.active
            ws.append(["name","country","city","rank","tuition_local","currency","tuition_usd","study_length_years","tuition_grant_available","tuition_grant_bond_years","interview_required","essay_or_portfolio_required","coop_or_internship_required","industry_links_score","exchange_opportunities_score","strengths","tags","intlRate","website","scholarship_available"])
            ws.append(["National University of Singapore","Singapore","Singapore",11,45000,"SGD",33000,4.0,True,3,True,True,True,9,8,"CS,Engineering,Business","Coop,Exchange",0.28,"https://www.nus.edu.sg",True])
            wb.save(sg_xlsx)
            print(f"ğŸ§ª å·²ç”Ÿæˆæ ·ä¾‹: {sg_xlsx}")

    ensure_sample_excels()

    if au_xlsx.exists():
        choice = input("æ˜¯å¦å¯¼å…¥æ¾³å¤§åˆ©äºšæ•°æ®ï¼ˆAUSTRALIA.xlsxï¼‰ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºAUç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            import_au_from_excel(db, str(au_xlsx), clear_choice == 'y')
    if uk_xlsx.exists():
        choice = input("æ˜¯å¦å¯¼å…¥è‹±å›½æ•°æ®ï¼ˆUK.xlsxï¼‰ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºUKç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            import_uk_from_excel(db, str(uk_xlsx), clear_choice == 'y')
    if sg_xlsx.exists():
        choice = input("æ˜¯å¦å¯¼å…¥æ–°åŠ å¡æ•°æ®ï¼ˆSINGAPORE.xlsxï¼‰ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºSGç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            import_sg_from_excel(db, str(sg_xlsx), clear_choice == 'y')
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆä»…ç¾å›½æ•°æ®é›†åˆï¼‰
    try:
    show_database_stats(db)
    except Exception:
        pass
    
    # è¯¢é—®æ˜¯å¦å¯¼å‡º
    export_choice = input("\næ˜¯å¦å¯¼å‡ºå½“å‰æ•°æ®åˆ°CSVï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
    if export_choice == 'y':
        export_to_csv(db)
    
    print("\nğŸ‰ æ•°æ®åº“ç®¡ç†å®Œæˆï¼")

if __name__ == "__main__":
    main() 