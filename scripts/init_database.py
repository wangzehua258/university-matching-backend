#!/usr/bin/env python3
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
æ”¯æŒCSVå¯¼å…¥ã€å¢é‡æ›´æ–°å’Œæ‰¹é‡æ“ä½œ
"""

import os
import sys
import json
import csv
from pathlib import Path
from pymongo import MongoClient, ASCENDING, DESCENDING
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

load_dotenv()

def connect_database():
    """è¿æ¥MongoDBæ•°æ®åº“"""
    mongo_url = os.getenv("MONGO_URL", "mongodb://localhost:27017")
    client = MongoClient(mongo_url)
    db = client.university_matcher
    return db

def create_indexes(db):
    """åˆ›å»ºæ•°æ®åº“ç´¢å¼•"""
    print("åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
    
    try:
        # ç”¨æˆ·é›†åˆç´¢å¼•
        db.users.create_index("created_at")
        print("âœ… ç”¨æˆ·ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  ç”¨æˆ·ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")
    
    try:
        # å¤§å­¦é›†åˆç´¢å¼• - æ›´æ–°ä»¥æ”¯æŒæ–°å­—æ®µ
        # å…ˆåˆ é™¤å¯èƒ½å†²çªçš„ç´¢å¼•
        try:
            db.universities.drop_index("name_1")
            print("ğŸ”„ åˆ é™¤æ—§åç§°ç´¢å¼•")
        except:
            pass
        
        # åˆ›å»ºæ–°ç´¢å¼•
        db.universities.create_index("name", unique=True)  # ç¡®ä¿å¤§å­¦åç§°å”¯ä¸€
        db.universities.create_index("country")
        db.universities.create_index("rank")
        db.universities.create_index([("country", ASCENDING), ("rank", ASCENDING)])
        db.universities.create_index("strengths")
        db.universities.create_index("tuition")
        db.universities.create_index("type")
        db.universities.create_index("schoolSize")
        db.universities.create_index("tags")
        
        # æ–°å¢å­—æ®µç´¢å¼•
        db.universities.create_index("supports_ed")
        db.universities.create_index("supports_ea")
        db.universities.create_index("supports_rd")
        db.universities.create_index("internship_support_score")
        db.universities.create_index("acceptanceRate")
        db.universities.create_index("intlRate")
        db.universities.create_index("state")
        db.universities.create_index("personality_types")
        
        print("âœ… å¤§å­¦ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  å¤§å­¦ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")
    
    try:
        # è¯„ä¼°ç»“æœç´¢å¼•
        db.parent_evaluations.create_index("user_id")
        db.parent_evaluations.create_index("created_at")
        db.student_personality_tests.create_index("user_id")
        db.student_personality_tests.create_index("created_at")
        print("âœ… è¯„ä¼°ç´¢å¼•åˆ›å»ºå®Œæˆ")
    except Exception as e:
        print(f"âš ï¸  è¯„ä¼°ç´¢å¼•åˆ›å»ºè·³è¿‡: {e}")
    
    print("ç´¢å¼•åˆ›å»ºå®Œæˆ")

def clean_boolean_value(value):
    """æ¸…ç†å¸ƒå°”å€¼"""
    if isinstance(value, str):
        value = value.strip().upper()
        if value in ['TRUE', 'T', 'YES', 'Y', '1']:
            return True
        elif value in ['FALSE', 'F', 'NO', 'N', '0']:
            return False
    return False

def clean_numeric_value(value, default=0, is_float=False):
    """æ¸…ç†æ•°å€¼"""
    if not value or value == '':
        return default
    
    try:
        if is_float:
            return float(value)
        else:
            return int(value)
    except (ValueError, TypeError):
        return default

def import_universities_from_csv(db, csv_file_path, clear_existing=False):
    """ä»CSVæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®"""
    if not os.path.exists(csv_file_path):
        print(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")
        return
    
    print(f"ä»CSVæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®: {csv_file_path}")
    
    # æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®
    if clear_existing:
        db.universities.delete_many({})
        print("å·²æ¸…ç©ºç°æœ‰æ•°æ®")
    
    with open(csv_file_path, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        universities = []
        updated_count = 0
        inserted_count = 0
        
        for row_num, row in enumerate(reader, 1):
            try:
                # æ•°æ®æ¸…æ´—å’Œè½¬æ¢ - é€‚é…schools.csvæ ¼å¼
                university = {
                    "name": row.get("name", "").strip(),
                    "country": row.get("country", "").strip(),
                    "state": row.get("state", "").strip(),
                    "rank": clean_numeric_value(row.get("rank"), 999),
                    "tuition": clean_numeric_value(row.get("tuition"), 0),
                    "intlRate": clean_numeric_value(row.get("intlRate"), 0, True),
                    "type": row.get("type", "private").strip(),
                    "schoolSize": row.get("schoolSize", "medium").strip(),
                    "strengths": [s.strip() for s in row.get("strengths", "").split(",") if s.strip()] if row.get("strengths") else [],
                    "gptSummary": row.get("gptSummary", "").strip(),
                    "logoUrl": "",  # æš‚æ—¶ç•™ç©ºï¼Œåç»­å¯ä»¥æ·»åŠ 
                    "acceptanceRate": clean_numeric_value(row.get("acceptanceRate"), 0, True),
                    "satRange": row.get("satRange", "").strip(),
                    "actRange": row.get("actRange", "").strip(),
                    "gpaRange": row.get("gpaRange", "").strip(),
                    "applicationDeadline": row.get("applicationDeadline", "").strip(),
                    "website": row.get("website", "").strip(),
                    "supports_ed": clean_boolean_value(row.get("supports_ed")),
                    "supports_ea": clean_boolean_value(row.get("supports_ea")),
                    "supports_rd": clean_boolean_value(row.get("supports_rd")),
                    "has_internship_program": clean_boolean_value(row.get("has_internship_program")),
                    "has_research_program": clean_boolean_value(row.get("has_research_program")),
                    "internship_support_score": clean_numeric_value(row.get("internship_support_score"), 5),
                    "personality_types": [s.strip() for s in row.get("personality_types", "").split(",") if s.strip()] if row.get("personality_types") else [],
                    "tags": [s.strip() for s in row.get("tags", "").split(",") if s.strip()] if row.get("tags") else []
                }
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                if not university["name"]:
                    print(f"âš ï¸  ç¬¬{row_num}è¡Œï¼šç¼ºå°‘å¤§å­¦åç§°ï¼Œè·³è¿‡")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆæŒ‰åç§°ï¼‰
                existing = db.universities.find_one({"name": university["name"]})
                if existing:
                    if clear_existing:
                        # å¦‚æœæ¸…ç©ºæ¨¡å¼ï¼Œç›´æ¥æ’å…¥
                        universities.append(university)
                    else:
                        # æ›´æ–°æ¨¡å¼ï¼Œæ›´æ–°ç°æœ‰è®°å½•
                        db.universities.update_one(
                            {"name": university["name"]}, 
                            {"$set": university}
                        )
                        updated_count += 1
                else:
                    universities.append(university)
                
            except Exception as e:
                print(f"âŒ ç¬¬{row_num}è¡Œæ•°æ®é”™è¯¯: {e}")
                print(f"   è¡Œæ•°æ®: {row}")
                continue
        
        # æ‰¹é‡æ’å…¥æ–°æ•°æ®
        if universities:
            try:
                result = db.universities.insert_many(universities)
                inserted_count = len(result.inserted_ids)
                print(f"âœ… æˆåŠŸæ’å…¥ {inserted_count} æ‰€æ–°å¤§å­¦")
            except Exception as e:
                print(f"âŒ æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
                # å°è¯•é€ä¸ªæ’å…¥
                for uni in universities:
                    try:
                        db.universities.insert_one(uni)
                        inserted_count += 1
                    except Exception as e2:
                        print(f"âŒ æ’å…¥å¤±è´¥ {uni['name']}: {e2}")
        
        print(f"ğŸ“Š å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted_count} æ‰€ï¼Œæ›´æ–° {updated_count} æ‰€")

def import_from_json(db, json_file_path, clear_existing=False):
    """ä»JSONæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®"""
    if not os.path.exists(json_file_path):
        print(f"JSONæ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return
    
    print(f"ä»JSONæ–‡ä»¶å¯¼å…¥å¤§å­¦æ•°æ®: {json_file_path}")
    
    try:
        with open(json_file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        if clear_existing:
            db.universities.delete_many({})
            print("å·²æ¸…ç©ºç°æœ‰æ•°æ®")
        
        if isinstance(data, list):
            universities = data
        elif isinstance(data, dict) and "universities" in data:
            universities = data["universities"]
        else:
            print("âŒ JSONæ ¼å¼é”™è¯¯ï¼šåº”è¯¥æ˜¯å¤§å­¦æ•°ç»„æˆ–åŒ…å«universitieså­—æ®µçš„å¯¹è±¡")
            return
        
        # å¤„ç†æ•°æ®
        inserted_count = 0
        updated_count = 0
        
        for uni in universities:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                existing = db.universities.find_one({"name": uni["name"]})
                if existing:
                    if clear_existing:
                        db.universities.insert_one(uni)
                        inserted_count += 1
                    else:
                        db.universities.update_one(
                            {"name": uni["name"]}, 
                            {"$set": uni}
                        )
                        updated_count += 1
                else:
                    db.universities.insert_one(uni)
                    inserted_count += 1
            except Exception as e:
                print(f"âŒ å¤„ç†å¤§å­¦ {uni.get('name', 'Unknown')} å¤±è´¥: {e}")
        
        print(f"ğŸ“Š JSONå¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted_count} æ‰€ï¼Œæ›´æ–° {updated_count} æ‰€")
        
    except Exception as e:
        print(f"âŒ JSONæ–‡ä»¶è¯»å–å¤±è´¥: {e}")

def export_to_csv(db, output_file="universities_export.csv"):
    """å¯¼å‡ºæ•°æ®åº“ä¸­çš„å¤§å­¦æ•°æ®åˆ°CSVæ–‡ä»¶"""
    print(f"å¯¼å‡ºå¤§å­¦æ•°æ®åˆ°: {output_file}")
    
    # åˆ›å»ºdataç›®å½•
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(exist_ok=True)
    
    output_path = data_dir / output_file
    
    # è·å–æ‰€æœ‰å¤§å­¦æ•°æ®
    universities = list(db.universities.find({}, {"_id": 0}).sort("rank", 1))
    
    if not universities:
        print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰å¤§å­¦æ•°æ®")
        return
    
    # å†™å…¥CSV
    with open(output_path, 'w', encoding='utf-8', newline='') as file:
        if universities:
            fieldnames = universities[0].keys()
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(universities)
    
    print(f"âœ… æˆåŠŸå¯¼å‡º {len(universities)} æ‰€å¤§å­¦åˆ° {output_path}")

def show_database_stats(db):
    """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
    print("-" * 40)
    
    total_universities = db.universities.count_documents({})
    print(f"æ€»å¤§å­¦æ•°é‡: {total_universities}")
    
    if total_universities > 0:
        # æ’ååˆ†å¸ƒ
        top10 = db.universities.count_documents({"rank": {"$lte": 10}})
        top20 = db.universities.count_documents({"rank": {"$lte": 20}})
        top50 = db.universities.count_documents({"rank": {"$lte": 50}})
        
        print(f"å‰10å: {top10} æ‰€")
        print(f"å‰20å: {top20} æ‰€")
        print(f"å‰50å: {top50} æ‰€")
        
        # ç±»å‹åˆ†å¸ƒ
        private_count = db.universities.count_documents({"type": "private"})
        public_count = db.universities.count_documents({"type": "public"})
        print(f"ç§ç«‹å¤§å­¦: {private_count} æ‰€")
        print(f"å…¬ç«‹å¤§å­¦: {public_count} æ‰€")
        
        # è§„æ¨¡åˆ†å¸ƒ
        small_count = db.universities.count_documents({"schoolSize": "small"})
        medium_count = db.universities.count_documents({"schoolSize": "medium"})
        large_count = db.universities.count_documents({"schoolSize": "large"})
        print(f"å°å‹å­¦æ ¡: {small_count} æ‰€")
        print(f"ä¸­å‹å­¦æ ¡: {medium_count} æ‰€")
        print(f"å¤§å‹å­¦æ ¡: {large_count} æ‰€")
        
        # å›½å®¶åˆ†å¸ƒ
        usa_count = db.universities.count_documents({"country": "USA"})
        print(f"ç¾å›½å¤§å­¦: {usa_count} æ‰€")
        
        # å¹³å‡å­¦è´¹
        avg_tuition = db.universities.aggregate([
            {"$group": {"_id": None, "avg": {"$avg": "$tuition"}}}
        ]).next()["avg"]
        print(f"å¹³å‡å­¦è´¹: ${avg_tuition:,.0f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤§å­¦æ•°æ®åº“ç®¡ç†å·¥å…·")
    print("=" * 50)
    
    # è¿æ¥æ•°æ®åº“
    try:
        db = connect_database()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºç´¢å¼•
    create_indexes(db)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_dir = Path(__file__).parent.parent / "data"
    data_dir.mkdir(exist_ok=True)
    
    # ä¼˜å…ˆæ£€æŸ¥schools.csvï¼Œç„¶åæ˜¯universities.csv
    schools_csv = data_dir / "schools.csv"
    universities_csv = data_dir / "universities.csv"
    json_file = data_dir / "universities.json"
    
    if schools_csv.exists():
        print(f"ğŸ“ æ‰¾åˆ°å­¦æ ¡æ•°æ®æ–‡ä»¶: {schools_csv}")
        choice = input("æ˜¯å¦ä»schools.csvå¯¼å…¥æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            clear_existing = clear_choice == 'y'
            import_universities_from_csv(db, str(schools_csv), clear_existing)
    elif universities_csv.exists():
        print(f"ğŸ“ æ‰¾åˆ°å¤§å­¦æ•°æ®æ–‡ä»¶: {universities_csv}")
        choice = input("æ˜¯å¦ä»universities.csvå¯¼å…¥æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            clear_existing = clear_choice == 'y'
            import_universities_from_csv(db, str(universities_csv), clear_existing)
    elif json_file.exists():
        print(f"ğŸ“ æ‰¾åˆ°JSONæ–‡ä»¶: {json_file}")
        choice = input("æ˜¯å¦ä»JSONå¯¼å…¥æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
        if choice != 'n':
            clear_choice = input("æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
            clear_existing = clear_choice == 'y'
            import_from_json(db, str(json_file), clear_existing)
    else:
        print("ğŸ“ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        print("è¯·å°†å¤§å­¦æ•°æ®æ”¾åœ¨ data/schools.csv æˆ– data/universities.csv ä¸­")
        return
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    show_database_stats(db)
    
    # è¯¢é—®æ˜¯å¦å¯¼å‡º
    export_choice = input("\næ˜¯å¦å¯¼å‡ºå½“å‰æ•°æ®åˆ°CSVï¼Ÿ(y/nï¼Œé»˜è®¤n): ").strip().lower()
    if export_choice == 'y':
        export_to_csv(db)
    
    print("\nğŸ‰ æ•°æ®åº“ç®¡ç†å®Œæˆï¼")

if __name__ == "__main__":
    main() 